# Escalabilidade Horizontal - Taxes Service

## Vis√£o Geral

O **Taxes Service** foi projetado para suportar **escalabilidade horizontal**, permitindo que m√∫ltiplas inst√¢ncias do servi√ßo rodem simultaneamente sem consumir mensagens em duplicata. O RabbitMQ gerencia automaticamente a distribui√ß√£o de mensagens entre os consumidores usando o padr√£o **Work Queue**.

## Como Funciona

### Modelo Work Queue do RabbitMQ

O RabbitMQ implementa nativamente o padr√£o de **Work Queue (Fila de Trabalho)**, onde:

1. **Uma √∫nica fila** cont√©m as mensagens
2. **M√∫ltiplos consumidores** (workers) conectam-se √† mesma fila
3. **RabbitMQ distribui** as mensagens usando algoritmo **round-robin**
4. **Cada mensagem** √© entregue a **APENAS UM consumidor**
5. **Sem duplica√ß√£o** de processamento

```
                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                              ‚îÇ     RabbitMQ        ‚îÇ
                              ‚îÇ                     ‚îÇ
                              ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ  ‚îÇtaxes_calculation‚îÇ  ‚îÇ
                        ‚îÇ     ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
                        ‚îÇ     ‚îÇ          ‚îÇ          ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇPublisher ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ
‚îÇ  (API)   ‚îÇ                             ‚îÇ Round-Robin Distribution
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                             ‚îÇ
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                        ‚îÇ                ‚îÇ                ‚îÇ
                        ‚ñº                ‚ñº                ‚ñº
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ Worker 1 ‚îÇ    ‚îÇ Worker 2 ‚îÇ    ‚îÇ Worker 3 ‚îÇ
                  ‚îÇ(Instance)‚îÇ    ‚îÇ(Instance)‚îÇ    ‚îÇ(Instance)‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  Msg 1, 4, 7...  Msg 2, 5, 8...  Msg 3, 6, 9...
```

## Configura√ß√µes Chave

### 1. prefetch_count=1

```python
channel.basic_qos(prefetch_count=1)
```

**O que faz:**
- Limita cada worker a processar **apenas 1 mensagem por vez**
- Worker s√≥ recebe pr√≥xima mensagem ap√≥s ACK da anterior
- Garante distribui√ß√£o justa de carga entre workers

**Benef√≠cios:**
- Workers mais r√°pidos n√£o ficam sobrecarregados
- Load balancing autom√°tico e justo
- Sem workers ociosos enquanto outros est√£o sobrecarregados

### 2. auto_ack=False (Manual Acknowledgment)

```python
channel.basic_consume(
    queue=RABBITMQ_TAXES_QUEUE,
    on_message_callback=process_message,
    auto_ack=False  # Manual acknowledgment
)
```

**O que faz:**
- Mensagem s√≥ √© removida da fila ap√≥s **ACK expl√≠cito**
- Se worker falhar, mensagem volta para a fila
- Outro worker pode processar a mensagem

**Benef√≠cios:**
- Garantia de processamento (at-least-once delivery)
- Toler√¢ncia a falhas
- Mensagens n√£o s√£o perdidas se worker cair

### 3. Fila Dur√°vel

```python
channel.queue_declare(queue=RABBITMQ_TAXES_QUEUE, durable=True)
```

**O que faz:**
- Fila persiste ap√≥s restart do RabbitMQ
- Mensagens marcadas como persistentes n√£o s√£o perdidas

**Benef√≠cios:**
- Alta disponibilidade
- Recupera√ß√£o ap√≥s falhas

## Escalando o Servi√ßo

### Op√ß√£o 1: Docker Compose Scale

```bash
# Escalar para 3 inst√¢ncias
docker compose up -d --scale taxes-service=3

# Verificar inst√¢ncias rodando
docker compose ps taxes-service

# Ver logs de todas as inst√¢ncias
docker compose logs -f taxes-service
```

### Op√ß√£o 2: M√∫ltiplos Containers Nomeados

Editar `docker-compose.yml`:

```yaml
services:
  taxes-service-1:
    build:
      context: ./services/taxes_service
    environment:
      - INSTANCE_NAME=taxes-service-1
      # ... outras vari√°veis
    networks:
      - app-network

  taxes-service-2:
    build:
      context: ./services/taxes_service
    environment:
      - INSTANCE_NAME=taxes-service-2
      # ... outras vari√°veis
    networks:
      - app-network

  taxes-service-3:
    build:
      context: ./services/taxes_service
    environment:
      - INSTANCE_NAME=taxes-service-3
      # ... outras vari√°veis
    networks:
      - app-network
```

### Op√ß√£o 3: Kubernetes (Produ√ß√£o)

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: taxes-service
spec:
  replicas: 3  # 3 inst√¢ncias
  selector:
    matchLabels:
      app: taxes-service
  template:
    metadata:
      labels:
        app: taxes-service
    spec:
      containers:
      - name: taxes-service
        image: taxes-service:latest
        env:
        - name: RABBITMQ_HOST
          value: "rabbitmq"
        - name: RABBITMQ_TAXES_QUEUE
          value: "taxes_calculation"
        # ... outras vari√°veis
```

## Garantias de Processamento

### ‚úÖ O que √â Garantido

1. **Sem Duplica√ß√£o**: Cada mensagem processada por APENAS um worker
2. **At-Least-Once**: Mensagem ser√° processada pelo menos uma vez
3. **Ordem na Fila**: FIFO (First In, First Out) dentro da fila
4. **Fairness**: Carga distribu√≠da igualmente entre workers

### ‚ö†Ô∏è O que N√ÉO √â Garantido

1. **Ordem Global**: Com m√∫ltiplos workers, ordem de conclus√£o pode variar
2. **Exactly-Once**: Em caso de falha ap√≥s processamento mas antes do ACK, pode reprocessar

## Exemplos Pr√°ticos

### Cen√°rio 1: 10 Mensagens, 1 Worker

```
Tempo: 10s por mensagem
Total: 100s (10 mensagens √ó 10s)

Worker 1: Msg1 ‚Üí Msg2 ‚Üí Msg3 ‚Üí Msg4 ‚Üí Msg5 ‚Üí Msg6 ‚Üí Msg7 ‚Üí Msg8 ‚Üí Msg9 ‚Üí Msg10
```

### Cen√°rio 2: 10 Mensagens, 3 Workers

```
Tempo: 10s por mensagem
Total: ~40s (distribu√≠do entre 3 workers)

Worker 1: Msg1 ‚Üí Msg4 ‚Üí Msg7 ‚Üí Msg10
Worker 2: Msg2 ‚Üí Msg5 ‚Üí Msg8
Worker 3: Msg3 ‚Üí Msg6 ‚Üí Msg9
```

**Ganho de Performance: 60% mais r√°pido! (100s ‚Üí 40s)**

### Cen√°rio 3: Worker Falha Durante Processamento

```
1. Worker 2 recebe Msg5
2. Worker 2 come√ßa processamento
3. Worker 2 FALHA antes de dar ACK
4. RabbitMQ detecta desconex√£o
5. RabbitMQ recoloca Msg5 na fila
6. Worker 1 ou 3 recebe e processa Msg5
```

## Monitoramento de M√∫ltiplas Inst√¢ncias

### 1. Via RabbitMQ Management UI

Acesse: `http://localhost:15672`

**Informa√ß√µes dispon√≠veis:**
- N√∫mero de consumidores conectados √† fila
- Taxa de mensagens/segundo por consumidor
- Mensagens pendentes (ready)
- Mensagens n√£o confirmadas (unacked)

```
Queues ‚Üí taxes_calculation
‚îú‚îÄ‚îÄ Overview
‚îÇ   ‚îú‚îÄ‚îÄ Total consumers: 3
‚îÇ   ‚îú‚îÄ‚îÄ Messages ready: 25
‚îÇ   ‚îî‚îÄ‚îÄ Messages unacked: 3 (1 por worker)
‚îî‚îÄ‚îÄ Consumers
    ‚îú‚îÄ‚îÄ Worker 1: prefetch=1, state=running
    ‚îú‚îÄ‚îÄ Worker 2: prefetch=1, state=running
    ‚îî‚îÄ‚îÄ Worker 3: prefetch=1, state=running
```

### 2. Via Docker Logs

```bash
# Ver logs de todas as inst√¢ncias misturadas
docker compose logs -f taxes-service

# Ver logs de uma inst√¢ncia espec√≠fica
docker logs -f i2a2_final-taxes-service-1
docker logs -f i2a2_final-taxes-service-2

# Filtrar logs de startup
docker compose logs taxes-service | grep "Starting RabbitMQ Consumer"

# Ver quantos workers conectados
docker compose logs taxes-service | grep "Waiting for messages" | wc -l
```

### 3. Via RabbitMQ CLI

```bash
# Listar consumidores de uma fila
docker exec -it rabbitmq rabbitmqctl list_consumers

# Estat√≠sticas da fila
docker exec -it rabbitmq rabbitmqctl list_queues name messages consumers

# Output esperado com 3 workers:
# taxes_calculation    10    3
```

## Estrat√©gias de Escalabilidade

### Auto-Scaling Baseado em Carga

#### M√©tricas para Monitorar:

1. **Queue Length** (Comprimento da Fila)
   - Se > 100 mensagens: escalar UP
   - Se < 10 mensagens: escalar DOWN

2. **Message Rate** (Taxa de Mensagens)
   - Incoming rate > Processing rate: escalar UP
   - Processing rate >> Incoming rate: escalar DOWN

3. **Worker CPU/Memory**
   - CPU > 80%: escalar UP
   - CPU < 20%: escalar DOWN

#### Exemplo de Auto-Scaling (Kubernetes HPA)

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: taxes-service-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: taxes-service
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: External
    external:
      metric:
        name: rabbitmq_queue_messages_ready
        selector:
          matchLabels:
            queue: taxes_calculation
      target:
        type: Value
        value: "50"
```

## Teste de Escalabilidade

### Script de Teste de Carga

```python
#!/usr/bin/env python3
"""
Script para testar escalabilidade do taxes-service
Envia m√∫ltiplas mensagens e monitora processamento
"""

import requests
import time
import concurrent.futures
from datetime import datetime

API_URL = "http://localhost:8002/calculate-taxes/"
CHAVE_ACESSO = "35250612345678000199550010000123451234567890"
NUM_REQUESTS = 100

def send_request(i):
    """Envia uma requisi√ß√£o de c√°lculo de taxas"""
    start = time.time()
    try:
        response = requests.post(
            API_URL,
            json={"chave_acesso": CHAVE_ACESSO},
            timeout=30
        )
        elapsed = time.time() - start
        return {
            'id': i,
            'status': response.status_code,
            'time': elapsed,
            'success': response.status_code == 200
        }
    except Exception as e:
        elapsed = time.time() - start
        return {
            'id': i,
            'status': 'error',
            'time': elapsed,
            'success': False,
            'error': str(e)
        }

def main():
    print(f"üöÄ Iniciando teste de carga: {NUM_REQUESTS} requisi√ß√µes")
    print(f"‚è∞ In√≠cio: {datetime.now()}")
    
    start_time = time.time()
    
    # Executar requisi√ß√µes em paralelo
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        results = list(executor.map(send_request, range(NUM_REQUESTS)))
    
    total_time = time.time() - start_time
    
    # An√°lise dos resultados
    successful = sum(1 for r in results if r['success'])
    failed = NUM_REQUESTS - successful
    avg_time = sum(r['time'] for r in results) / NUM_REQUESTS
    
    print(f"\nüìä Resultados:")
    print(f"   Total de requisi√ß√µes: {NUM_REQUESTS}")
    print(f"   Sucesso: {successful} ({successful/NUM_REQUESTS*100:.1f}%)")
    print(f"   Falhas: {failed} ({failed/NUM_REQUESTS*100:.1f}%)")
    print(f"   Tempo total: {total_time:.2f}s")
    print(f"   Tempo m√©dio/req: {avg_time:.2f}s")
    print(f"   Throughput: {NUM_REQUESTS/total_time:.2f} req/s")
    print(f"‚è∞ Fim: {datetime.now()}")

if __name__ == "__main__":
    main()
```

### Executar Teste

```bash
# Teste com 1 worker
docker compose up -d --scale taxes-service=1
python3 test_load.py

# Teste com 3 workers
docker compose up -d --scale taxes-service=3
python3 test_load.py

# Teste com 5 workers
docker compose up -d --scale taxes-service=5
python3 test_load.py
```

### Resultados Esperados

```
1 Worker:  100 req em ~100s = 1.0 req/s
3 Workers: 100 req em ~35s  = 2.9 req/s (2.9x faster)
5 Workers: 100 req em ~22s  = 4.5 req/s (4.5x faster)
```

## Boas Pr√°ticas

### 1. Dimensionamento Correto

```bash
# Regra geral:
# Workers = min(CPU_CORES, EXPECTED_LOAD / AVG_PROCESSING_TIME)

# Exemplo:
# - 4 CPU cores dispon√≠veis
# - 100 msg/min esperadas
# - 10s tempo m√©dio de processamento
# Workers recomendados: 2-4
```

### 2. Monitoramento Cont√≠nuo

- Alertas para fila muito cheia (> 1000 mensagens)
- Alertas para consumidores desconectados
- M√©tricas de throughput e lat√™ncia

### 3. Graceful Shutdown

Os workers j√° implementam graceful shutdown:
```python
except KeyboardInterrupt:
    logger.info("\n‚ö†Ô∏è  Interrupted by user")
finally:
    if connection and not connection.is_closed:
        connection.close()
```

### 4. Health Checks

```bash
# Verificar se workers est√£o consumindo
curl http://localhost:8002/health

# Verificar estat√≠sticas
curl http://localhost:8002/status
```

## Limita√ß√µes e Considera√ß√µes

### 1. Ordem de Processamento

Com m√∫ltiplos workers, **n√£o h√° garantia de ordem global** de conclus√£o:
- Msg1 pode terminar depois de Msg3
- Se ordem √© cr√≠tica, use 1 worker ou implemente sequenciamento

### 2. Sess√µes e Estado Compartilhado

- Workers devem ser **stateless**
- N√£o compartilhar estado entre workers
- Usar banco de dados para estado persistente

### 3. Idempot√™ncia

Implemente opera√ß√µes **idempotentes**:
- Processar mesma mensagem 2x deve ter mesmo resultado
- Importante para caso de reprocessamento ap√≥s falha

```python
def calculate_taxes(data):
    """Fun√ß√£o idempotente - pode ser chamada m√∫ltiplas vezes"""
    chave_acesso = data['nota_fiscal']['chave_acesso']
    
    # Verificar se j√° foi processado
    if already_processed(chave_acesso):
        logger.info(f"J√° processado: {chave_acesso}")
        return get_cached_result(chave_acesso)
    
    # Processar
    result = do_calculation(data)
    
    # Salvar resultado
    save_result(chave_acesso, result)
    
    return result
```

## Compara√ß√£o: Onboarding Service

O **Onboarding Service** usa exatamente o mesmo padr√£o:

| Caracter√≠stica | Onboarding Service | Taxes Service |
|----------------|-------------------|---------------|
| Fila Principal | `notas_fiscais` | `taxes_calculation` |
| DLQ | `notas_fiscais_dlq` | `taxes_calculation_dlq` |
| prefetch_count | 1 | 1 |
| auto_ack | False | False |
| Escal√°vel | ‚úÖ Sim | ‚úÖ Sim |
| Load Balance | ‚úÖ Autom√°tico | ‚úÖ Autom√°tico |

Ambos os servi√ßos podem ser escalados da mesma forma!

## Conclus√£o

‚úÖ **O mecanismo atual J√Å est√° correto!**

O RabbitMQ com o padr√£o **Work Queue** resolve automaticamente:
- ‚úÖ Distribui√ß√£o de mensagens (round-robin)
- ‚úÖ Sem duplica√ß√£o de processamento
- ‚úÖ Load balancing autom√°tico
- ‚úÖ Toler√¢ncia a falhas
- ‚úÖ Fair dispatch com prefetch_count=1

**N√£o √© necess√°rio implementar grupos ou coordena√ß√£o adicional.**

Basta escalar o n√∫mero de inst√¢ncias:
```bash
docker compose up -d --scale taxes-service=5
```

E o RabbitMQ cuida do resto! üéâ

